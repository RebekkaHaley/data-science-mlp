{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Layer Neural Network | Text Colour Predictor\n",
    "\n",
    "Task:\n",
    "- Build a scalable feed-forward neural network.\n",
    "- Input values of RGB 'background colour'.\n",
    "- Predict if light or dark coloured text should be used over the RGB colour to make the text readable.\n",
    "\n",
    "Task mapping:\n",
    "- Objects of interest: RGB vectors (3 $\\times$ 1 dimension).\n",
    "- Labels: light text versus dark text.\n",
    "\n",
    "Resources:\n",
    "- [Feed-forward NN playground](https://playground.tensorflow.org)\n",
    "- [Activation functions](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import numpy as np # For linear algebra.\n",
    "import pandas as pd # For data processing, CSV file I/O (e.g. pd.read_csv).\n",
    "import matplotlib.pyplot as plt # For data visualisation.\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageEnhance # For data visualisation.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB class and tool functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error(Exception):\n",
    "    \"\"\"Base class for exceptions in this module.\"\"\"\n",
    "    pass\n",
    "\n",
    "class InputError(Error):\n",
    "    '''Exception raised for errors in the input.\n",
    "\n",
    "    Attributes:\n",
    "        expr -- Input expression in which the error occurred.\n",
    "        msg  -- Explanation of the error.'''\n",
    "    def __init__(self, expr, msg):\n",
    "        self.expr = expr\n",
    "        self.msg = msg\n",
    "\n",
    "class RGB():\n",
    "    '''Defined with values for RGB as input.\n",
    "    \n",
    "    Attributes:\n",
    "        RGB -- Input RGB values should range from 0 to 255.\n",
    "        hex -- Automatically converts RGB to hex values.'''\n",
    "    def __init__(self, R, G, B):\n",
    "        for X in [R, G, B]:\n",
    "            if (X < 0) or (X > 255):\n",
    "                raise InputError(X, 'Not an RGB value.')\n",
    "        self.R = R\n",
    "        self.G = G\n",
    "        self.B = B\n",
    "        self.RGB = (R, G, B)\n",
    "        self.hex = '#{:02X}{:02X}{:02X}'.format(self.R,self.G,self.B)\n",
    "\n",
    "def generate_RGB_data(X, extreme=False, extreme_magnitude=200):\n",
    "    '''Generates a list filled with X number of RGB class values.\n",
    "    Optional: generate cols that are v. dark + v. light for training.\n",
    "    \n",
    "    Attributes:\n",
    "        X -- Number of desired RGB instances.\n",
    "        extreme -- Boolean to generate v. dark + v. light cols.\n",
    "        extreme_magnitude -- Int between 1 and 254.'''\n",
    "    if extreme == True:\n",
    "        cols = []\n",
    "        for x in range(X):\n",
    "            minimum = extreme_magnitude*(x%2)\n",
    "            maximum = 255-(extreme_magnitude*(not x%2))\n",
    "            rgb = RGB(np.random.randint(low=minimum, high=maximum),\n",
    "                      np.random.randint(low=minimum, high=maximum),\n",
    "                      np.random.randint(low=minimum, high=maximum))\n",
    "            cols.append(rgb)\n",
    "        return cols\n",
    "                        \n",
    "    else:\n",
    "        return [RGB(np.random.randint(0, 255),\n",
    "                    np.random.randint(0, 255),\n",
    "                    np.random.randint(0, 255))\n",
    "                for i in range(X)]\n",
    "\n",
    "def display_RGB_colour(colour, font_col='#000'):\n",
    "    '''Will draw a box of given colour;\n",
    "    and fill with text of given font colour.\n",
    "    \n",
    "    Attributes:\n",
    "        colour -- String containing a RGB or hex value.\n",
    "        font_col -- String containing a RGB or hex value.'''\n",
    "    img = Image.new(mode='RGB', size=(100, 100), color=colour)\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "    img_draw.text((36, 45), 'Text', fill=font_col)\n",
    "    plt.imshow(img)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test the RGB class and data visualisation tool functions:\n",
    "colours = generate_RGB_data(X=1, extreme=True, extreme_magnitude=200)\n",
    "\n",
    "for colour in colours:\n",
    "    print('RGB:', colour.RGB, 'Hex:', colour.hex)\n",
    "    display_RGB_colour(colour=colour.RGB, font_col='#fff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data:\n",
    "\n",
    "NB: Change \"extreme_magnitude\" to adjust the level of noise. Default has no noise (i.e. easy to model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42) # Optional: set seed for data generation.\n",
    "extreme_magnitude = 100 # Optional: set magnitude lower for higher error.\n",
    "\n",
    "data = pd.DataFrame([x.RGB for x in generate_RGB_data(X=500,\n",
    "                                                      extreme=True,\n",
    "                                                      extreme_magnitude=extreme_magnitude)],\n",
    "                     columns=['R', 'G', 'B'])\n",
    "\n",
    "display('Training set:', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Labels\n",
    "\n",
    "NB: This the 'lazy' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = AgglomerativeClustering(n_clusters=2, linkage='ward').fit(data.values)\n",
    "y = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, label in enumerate(y[:2]):\n",
    "    \n",
    "    if label == 1: # NB: must check for most appriate label-to-class assignment.\n",
    "        print('---> light text')\n",
    "        display_RGB_colour(colour=tuple(data.iloc[i, :]), font_col='#fff')\n",
    "        \n",
    "    else:\n",
    "        print('---> dark text')\n",
    "        display_RGB_colour(colour=tuple(data.iloc[i, :]), font_col='#000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split data into training & testing sets:\n",
    "train_temp, test_temp = train_test_split(data.join(pd.Series(y, name='y')))\n",
    "\n",
    "display(train_temp.head())\n",
    "display(test_temp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "train = pd.DataFrame(np.insert(normalize(X=train_temp.values[:, :3]), 3, train_temp.values[:, 3], axis=1),\n",
    "                     index=train_temp.index,\n",
    "                     columns=train_temp.columns)\n",
    "\n",
    "test = pd.DataFrame(np.insert(normalize(X=test_temp.values[:, :3]), 3, test_temp.values[:, 3], axis=1),\n",
    "                    index=test_temp.index,\n",
    "                    columns=test_temp.columns)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neuron class:\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, X, y, bias=1, eta=0.1, n_nodes=2, n_layers=2, Ws=None, linear=False):\n",
    "        '''Initialise internal state of network. CAUTION: when setting own Ws param,\n",
    "        make sure the matrix dimensions are correct.\n",
    "        \n",
    "        Attributes:\n",
    "        X -- Initial input vector; should be a numpy array or matrix.\n",
    "        y -- Initial y_true; should be numpy array.\n",
    "        Ws -- Optional. If given should be a list of numpy arrays.'''\n",
    "        # Create list of LAYERS:\n",
    "        self.layers = []\n",
    "        self.layers.append(X) # Append input layer.\n",
    "        for i in range(n_layers-1):\n",
    "            self.layers.append(np.zeros((n_nodes, 1))) # Append hidden layers.\n",
    "        self.layers.append(np.zeros(y.shape)) # Append output layer.\n",
    "\n",
    "        # Create list of WEIGHTS:\n",
    "        if Ws is None:\n",
    "            self.Ws = []\n",
    "            for i in range(n_layers):\n",
    "                self.Ws.append(np.random.rand(self.layers[i+1].shape[0], self.layers[i].shape[0]))\n",
    "        else:\n",
    "            self.Ws = Ws\n",
    "\n",
    "        # Create list of BIASES:\n",
    "        self.biases = []\n",
    "        for i in range(n_layers):\n",
    "            self.biases.append(np.ones((self.Ws[i].shape[0], self.layers[i].shape[1]))*bias) # Multiply bias.\n",
    "\n",
    "        # Set the other parameters:\n",
    "        self.y_true = y\n",
    "        self.eta = eta\n",
    "        self.linear = linear\n",
    "        self.n_layers = n_layers\n",
    "    \n",
    "    def activ_func(self, x):\n",
    "        '''Activation function used during forward pass.'''\n",
    "        # For linear:\n",
    "        if self.linear is True:\n",
    "            return x\n",
    "        # For sigmoid:\n",
    "        else:\n",
    "            return 1.0/(1.0 + np.exp(-x))\n",
    "    \n",
    "    def forwardpass(self):\n",
    "        '''Runs the forward pass algorithm using the internal state (via self).'''\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers[i+1] = self.activ_func(np.dot(self.Ws[i], self.layers[i]) + self.biases[i])\n",
    "        \n",
    "    def activ_deriv(self, x):\n",
    "        '''Derivative of the activation function used during backpropagation.'''\n",
    "        # For linear:\n",
    "        if self.linear is True:\n",
    "            return 1\n",
    "        # For sigmoid:\n",
    "        else:\n",
    "            return self.activ_func(x)*(1-self.activ_func(x))\n",
    "    \n",
    "    def error_deriv(self):\n",
    "        '''Derivative of the error function used during backpropagation.'''\n",
    "        return -(self.y_true-self.layers[-1])\n",
    "    \n",
    "    def error(self):\n",
    "        '''Error function.'''\n",
    "        return ((self.y_true-self.layers[-1])**2)*0.5\n",
    "    \n",
    "    def backprop(self):\n",
    "        '''Runs backpropagation algorithm using the internal state (via self):\n",
    "        (1) applies chain rule to find derivative of loss function;\n",
    "        (2) updates the weights and biases with the gradient of the loss function.'''\n",
    "        # Initialise lists to contain deltas:\n",
    "        deltas = []\n",
    "        \n",
    "        # Iterate over n number of layers and calculate delta:\n",
    "        for i in reversed(range(self.n_layers)): # NB: reversed for backpropagation.\n",
    "            # Calculate the deriv wrt. activation:\n",
    "            d_activ = self.activ_deriv(x=np.dot(self.Ws[i], self.layers[i]))\n",
    "            \n",
    "            # Delta for output layer:\n",
    "            if i == self.n_layers-1:\n",
    "                delta = self.error_deriv() * d_activ\n",
    "                \n",
    "            # Delta for subsequent layers:\n",
    "            else:\n",
    "                delta = np.dot(deltas[0].T, self.Ws[i+1]).T * d_activ # NB: uses the prev delta and prev layer.\n",
    "                \n",
    "            # Save delta to list:\n",
    "            deltas.insert(0, delta) # NB: undo reversed order.\n",
    "\n",
    "        # Iterate over deltas and apply both kinds of updates:\n",
    "        for i in range(self.n_layers):\n",
    "            # Update weight:\n",
    "            self.Ws[i] += -self.eta * np.dot(deltas[i], self.layers[i].T)\n",
    "            \n",
    "            # Update bias:\n",
    "            self.biases[i] += -self.eta * deltas[i] * self.biases[i]\n",
    "\n",
    "    def fit(self, Xs, ys, iterations=1):\n",
    "        '''Applies the forward pass and backpropagation algorithms in sequence to fit given training data.\n",
    "        \n",
    "        Attributes:\n",
    "        iterations -- Number of times to repeat the sequence over whole dataset, aka epochs.'''\n",
    "        y_preds = []\n",
    "        \n",
    "        for iteration in range(iterations): # Per iteration.\n",
    "            for i, X in enumerate(Xs): # Per data point.\n",
    "                # Reset inputs:\n",
    "                self.layers[0] = X  # X assigned to input layer.\n",
    "                self.y_true = ys[i] # y assigned to y_true.\n",
    "                \n",
    "                self.forwardpass()\n",
    "                self.backprop()\n",
    "                \n",
    "                # Save the final interation of output layer:\n",
    "                if iteration == iterations-1:\n",
    "                    y_preds.append(self.layers[-1])\n",
    "                    \n",
    "        return np.array(y_preds)\n",
    "    \n",
    "    def predict(self, Xs):\n",
    "        '''Applies forward pass using the internal state to the given input data (Xs).\n",
    "        \n",
    "        Attributes:\n",
    "        Xs -- Input data.'''\n",
    "        y_preds = []\n",
    "        \n",
    "        for X in Xs: # Per data point.\n",
    "            self.layers[0] = X # X assigned to input layer.\n",
    "            self.forwardpass()\n",
    "            y_preds.append(self.layers[-1])\n",
    "            \n",
    "        return np.array(y_preds)\n",
    "    \n",
    "    def display_test_results(self, Xs, y_preds):\n",
    "        '''Will plot a figure of a given colour (via Xs) and its predicted text colour (via y_preds).\n",
    "        NB: specific to the \"text predictor\" scenario.\n",
    "        \n",
    "        Attributes:\n",
    "        Xs -- Input data.\n",
    "        y_preds -- Predicted colours.'''\n",
    "        for i, y in enumerate(y_preds):\n",
    "            if y == 0:\n",
    "                print('\\n--->\\t{}:\\tlight text'.format(y))\n",
    "                display_RGB_colour(colour=tuple(Xs[i, :]), font_col='#fff')\n",
    "\n",
    "            else:\n",
    "                print('\\n--->\\t{}:\\dark text'.format(y))\n",
    "                display_RGB_colour(colour=tuple(Xs[i, :]), font_col='#000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use NN on a dummy example:\n",
    "\n",
    "NB: the idea behind using the dummy example is tha tit is easy to calculate by hand.\n",
    "\n",
    "The results should be as follows:\n",
    "- First ***forward pass*** output: $\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}$\n",
    "- ***Backpropagation***...\n",
    "    - ... hidden layer update: $\\begin{bmatrix} -1 & 0.1 \\\\ 0 & 0.8 \\end{bmatrix}$\n",
    "    - ... output layer update: $\\begin{bmatrix} 0.9 & -0.2 \\\\ -1.2 & 0.6 \\end{bmatrix}$\n",
    "- Second ***forward pass*** output: $\\begin{bmatrix} 1.66 \\\\ 0.32 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup inputs:\n",
    "X = np.array([0, 1]).reshape((2,1))\n",
    "y = np.array([1, 0]).reshape((2,1))\n",
    "Ws = [np.array([[-1, 0], [0, 1]], dtype=float),\n",
    "      np.array([[1, 0], [-1, 1]], dtype=float)]\n",
    "\n",
    "# Initialise NN:\n",
    "NN = NeuralNetwork(X=X,\n",
    "                   y=y,\n",
    "                   bias=1,\n",
    "                   eta=0.1,\n",
    "                   n_nodes=2,\n",
    "                   n_layers=2,\n",
    "                   Ws=Ws,\n",
    "                   linear=True)\n",
    "\n",
    "# Use NN:\n",
    "NN.forwardpass()\n",
    "print('\\nForward Pass:\\noutput:\\n{}'.format(NN.layers[-1]))\n",
    "\n",
    "NN.backprop()\n",
    "print('\\nBackpropagation:\\nhidden:\\n{}\\noutput:\\n{}'.format(NN.Ws[-2], NN.Ws[-1]))\n",
    "\n",
    "NN.forwardpass()\n",
    "print('\\nForward Pass:\\noutput:\\n{}'.format(NN.layers[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup inputs:\n",
    "input_X = train.values[0, :3].reshape((3,1))\n",
    "input_y = train.values[0, 3].reshape((1,1))\n",
    "print('X:\\n{}\\ny:\\n{}'.format(input_X, input_y))\n",
    "\n",
    "# Initialise NN:\n",
    "NN = NeuralNetwork(X=input_X,\n",
    "                   y=input_y,\n",
    "                   bias=1,\n",
    "                   eta=0.1,\n",
    "                   n_nodes=5,\n",
    "                   n_layers=3,\n",
    "                   Ws=None,\n",
    "                   linear=False)\n",
    "\n",
    "# Use NN:\n",
    "NN.forwardpass()\n",
    "print('\\nForward Pass:\\noutput:\\n{}'.format(NN.layers[-1]))\n",
    "\n",
    "NN.backprop()\n",
    "print('\\n...')\n",
    "\n",
    "NN.forwardpass()\n",
    "print('\\nForward Pass:\\noutput:\\n{}'.format(NN.layers[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Setup inputs:\n",
    "tr_i = train.shape[0]\n",
    "train_Xs = train.values[:, :3].reshape((tr_i, 3, 1))\n",
    "train_ys = train.values[:,  3].reshape((tr_i, 1, 1))\n",
    "print('Shapes of inputs:', train_Xs.shape, train_ys.shape)\n",
    "\n",
    "# Train NN:\n",
    "train_y_preds = NN.fit(Xs=train_Xs, ys=train_ys, iterations=1000)\n",
    "print('Shape of y_preds:', train_y_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check training predictions:\n",
    "print(train_y_preds.reshape(tr_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NN layers:\n",
    "for i, layer in enumerate(NN.layers):\n",
    "    print('Layer #{}.\\n{}\\n'.format(i, layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training results:\n",
    "# NB: the y predictions are rounded!\n",
    "train_results = pd.DataFrame({'y_true': train.y.values,\n",
    "                              'y_pred': np.round(train_y_preds).reshape((tr_i,)).astype(int),\n",
    "                              'same': train.y.values == np.round(train_y_preds).reshape((tr_i,)).astype(int)})\n",
    "\n",
    "display(train_results.loc[train_results.y_pred==1])\n",
    "display(train_results.loc[train_results.y_pred==0])\n",
    "\n",
    "print('{}% error'.format(round(len(train_results[train_results.same==False]) / len(train_results) * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NN on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup inputs:\n",
    "te_i = test.shape[0]\n",
    "test_Xs = test.values[:, :3].reshape((te_i, 3, 1))\n",
    "test_ys = test.values[:,  3].reshape((te_i, 1, 1))\n",
    "print('Shapes of inputs:', test_Xs.shape, test_ys.shape)\n",
    "\n",
    "# Test NN:\n",
    "test_y_preds = NN.predict(Xs=test_Xs)\n",
    "print('Shape of y_preds:', test_y_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check testing predictions:\n",
    "print(test_y_preds.reshape(test_y_preds.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing results:\n",
    "# NB: the y predictions are rounded!\n",
    "test_results = pd.DataFrame({'y_true': test.y.values,\n",
    "                             'y_pred': np.round(test_y_preds).reshape((te_i,)).astype(int),\n",
    "                             'same': test.y.values == np.round(test_y_preds).reshape((te_i,)).astype(int)})\n",
    "\n",
    "display(test_results.head(15))\n",
    "\n",
    "print('{}% error'.format(round(len(test_results[test_results.same==False]) / len(test_results) * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare against NN via scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the sklearn neural network\n",
    "sklearn_NN = MLPClassifier(activation='logistic',\n",
    "                           solver='sgd',\n",
    "                           max_iter=1000) # NB: 'logistic' and stochastic gd chosen for fair comparison.\n",
    "\n",
    "# View description\n",
    "sklearn_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise parameters via a gridsearch:\n",
    "sklearn_grid = GridSearchCV(estimator=sklearn_NN,\n",
    "                            param_grid={'hidden_layer_sizes': [5, 50, 100],\n",
    "                                        'learning_rate_init': [0.1, 0.01, 0.001],\n",
    "                                        'alpha': [0.1, 0.01, 0.001]},\n",
    "                            cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train sklearn NN:\n",
    "sklearn_grid.fit(X=train.iloc[:, :3].values,\n",
    "                 y=train.y.values)\n",
    "\n",
    "print('best parameters:\\t{}'.format(sklearn_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sklearn NN:\n",
    "sklearn_y_preds = sklearn_grid.predict(X=test.iloc[:, :3].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the sklearn predictions:\n",
    "sklearn_results = pd.DataFrame({'y_true': test.y.values,\n",
    "                                'y_pred': sklearn_y_preds,\n",
    "                                'same': test.y.values == sklearn_y_preds})\n",
    "\n",
    "display(sklearn_results.head(10))\n",
    "\n",
    "# Print error:\n",
    "print('{}% error'.format(round(len(sklearn_results[sklearn_results.same==False]) / len(sklearn_results) * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

## Welcome

This repo contains code pertaining to a machine learning tool called the multilayer perceptron (MLP). It has been implemented in both simple 2-layer and n-layer versions, and is also known as a feed-forward neural network.

This project originally began as an exercise during a university module, but has since been fleshed out into a two-layer version and an n-layer version.

## Multilayer perceptron

MLPs involve two stages: (1) the forward pass, and (2) back-propagation.

MLPs are based on the idea of taking multiple single perceptrons and connecting them in a network. The input is turned into output during the forward pass via matrix multiplication. Subsequently, the weights are updated during back-propagation, where gradient descent and differentiation via the chain rule are utilised.

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Layer Neural Network | Text Colour Predictor\n",
    "\n",
    "Task:\n",
    "- Build a scalable feed-forward neural network.\n",
    "- Input values of RGB 'background colour'.\n",
    "- Predict if light or dark coloured text should be used over the RGB colour to make the text readable.\n",
    "\n",
    "Task mapping:\n",
    "- Objects of interest: RGB vectors (3 $\\times$ 1 dimension).\n",
    "- Labels: '1' light text versus '0' dark text.\n",
    "\n",
    "Resources:\n",
    "- [Feed-forward NN playground](https://playground.tensorflow.org)\n",
    "- [7 types of activation functions](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/)\n",
    "- [Activation Functions in Neural Networks](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)\n",
    "- [Comprehensive list of activation functions...](https://stats.stackexchange.com/questions/115258/comprehensive-list-of-activation-functions-in-neural-networks-with-pros-cons)\n",
    "- [A Practical Guide to ReLU](https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7)\n",
    "- [What should I do when my neural network doesn't learn?](https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scripts\n",
    "from rgb import *\n",
    "from n_layer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test the RGB class and data visualisation tool functions:\n",
    "colours = generate_rgb_data(size=1, extreme=True, extreme_magnitude=200)\n",
    "\n",
    "for colour in colours:\n",
    "    colour.generate_img(font_col='#fff')\n",
    "    plt.imshow(colour.img)\n",
    "    print('RGB:', colour.RGB, 'Hex:', colour.hex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "NB: Change \"extreme_magnitude\" to adjust the level of noise. Default has no noise (i.e. easy to model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42) # Optional: set seed for data generation.\n",
    "extreme_magnitude = 100 # Optional: set magnitude lower for higher error.\n",
    "\n",
    "colours = generate_rgb_data(size=500, extreme=True, extreme_magnitude=extreme_magnitude)\n",
    "data = pd.DataFrame([x.RGB for x in colours], columns=['R', 'G', 'B'])\n",
    "\n",
    "display('Training set:', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Labels with 'lazy' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = AgglomerativeClustering(n_clusters=2, linkage='ward').fit(data.values)\n",
    "y = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, label in enumerate(y[499:]):\n",
    "    if label == 1:  # NB: must check for most appriate label-to-class assignment.\n",
    "        print('---> light text')\n",
    "        colours[i].generate_img(font_col='#fff')\n",
    "    else:\n",
    "        print('---> dark text')\n",
    "        colours[i].generate_img(font_col='#000')\n",
    "    plt.imshow(colours[i].img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split data into training & testing sets:\n",
    "train_temp, test_temp = train_test_split(data.join(pd.Series(y, name='y')))\n",
    "\n",
    "display(train_temp.head(5))\n",
    "display(test_temp.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(np.insert(normalize(X=train_temp.values[:, :3]), 3, train_temp.values[:, 3], axis=1),\n",
    "                     index=train_temp.index,\n",
    "                     columns=train_temp.columns)\n",
    "\n",
    "test = pd.DataFrame(np.insert(normalize(X=test_temp.values[:, :3]), 3, test_temp.values[:, 3], axis=1),\n",
    "                    index=test_temp.index,\n",
    "                    columns=test_temp.columns)\n",
    "\n",
    "display(train.head(5))\n",
    "display(test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use NN on a dummy example\n",
    "\n",
    "NB: the idea behind using the dummy example is that it is easy to calculate by hand.\n",
    "\n",
    "The results should be as follows:\n",
    "- First ***forward pass*** output: $\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}$\n",
    "- ***Backpropagation***...\n",
    "    - ... hidden layer update: $\\begin{bmatrix} -1 & 0.1 \\\\ 0 & 0.8 \\end{bmatrix}$\n",
    "    - ... output layer update: $\\begin{bmatrix} 0.9 & -0.2 \\\\ -1.2 & 0.6 \\end{bmatrix}$\n",
    "- Second ***forward pass*** output: $\\begin{bmatrix} 1.66 \\\\ 0.32 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup inputs:\n",
    "X = np.array([0, 1]).reshape((2,1))\n",
    "y = np.array([1, 0]).reshape((2,1))\n",
    "Ws = [np.array([[-1, 0], [0, 1]], dtype=float),\n",
    "      np.array([[1, 0], [-1, 1]], dtype=float)]\n",
    "\n",
    "# Initialise NN:\n",
    "NN = NeuralNetwork(x_input=X,\n",
    "                   y_input=y,\n",
    "                   bias=1,\n",
    "                   eta=0.1,\n",
    "                   n_nodes=2,\n",
    "                   n_layers=2,\n",
    "                   weights=Ws,\n",
    "                   linear=True)\n",
    "\n",
    "# Use NN:\n",
    "NN.forwardpass()\n",
    "print('\\nForward Pass:\\noutput:\\n{}'.format(NN.layers[-1]))\n",
    "\n",
    "NN.backprop()\n",
    "print('\\nBackpropagation:\\nhidden:\\n{}\\noutput:\\n{}'.format(NN.weights[-2], NN.weights[-1]))\n",
    "\n",
    "NN.forwardpass()\n",
    "print('\\nForward Pass:\\noutput:\\n{}'.format(NN.layers[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup inputs:\n",
    "input_X = train.values[0, :3].reshape((3,1))\n",
    "input_y = train.values[0, 3].reshape((1,1))\n",
    "print('X:\\n{}\\ny:\\n{}'.format(input_X, input_y))\n",
    "\n",
    "# Initialise NN:\n",
    "NN = NeuralNetwork(x_input=input_X,\n",
    "                   y_input=input_y,\n",
    "                   bias=1,\n",
    "                   eta=0.1,\n",
    "                   n_nodes=5,\n",
    "                   n_layers=3,\n",
    "                   weights=None,\n",
    "                   linear=False)\n",
    "\n",
    "# Use NN:\n",
    "NN.forwardpass()\n",
    "print('\\nForward Pass:\\noutput:\\n{}'.format(NN.layers[-1]))\n",
    "\n",
    "NN.backprop()\n",
    "print('\\n...')\n",
    "\n",
    "NN.forwardpass()\n",
    "print('\\nForward Pass:\\noutput:\\n{}'.format(NN.layers[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup inputs:\n",
    "tr_i = train.shape[0]\n",
    "train_Xs = train.values[:, :3].reshape((tr_i, 3, 1))\n",
    "train_ys = train.values[:,  3].reshape((tr_i, 1, 1))\n",
    "print('Shapes of inputs:', train_Xs.shape, train_ys.shape)\n",
    "\n",
    "# Train NN:\n",
    "train_y_preds, train_y_errors = NN.fit(x_inputs=train_Xs, y_inputs=train_ys, iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check training predictions:\n",
    "print('Shape of y_preds:', train_y_preds.shape)\n",
    "print(train_y_preds.reshape(tr_i)[:5])\n",
    "\n",
    "# Check traininng errors:\n",
    "print('Shape of y_errors:', train_y_errors.shape)\n",
    "print(train_y_errors.reshape(tr_i)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NN layers:\n",
    "for i, layer in enumerate(NN.layers):\n",
    "    print('Layer #{}.\\n{}\\n'.format(i, layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training results:\n",
    "# NB: the y predictions are rounded!\n",
    "train_results = pd.DataFrame({'y_true': train.y.values,\n",
    "                              'y_pred': np.round(train_y_preds).reshape((tr_i,)).astype(int),\n",
    "                              'same': train.y.values == np.round(train_y_preds).reshape((tr_i,)).astype(int)})\n",
    "\n",
    "display(train_results.loc[train_results.y_pred==1].head(5))\n",
    "display(train_results.loc[train_results.y_pred==0].head(5))\n",
    "\n",
    "print('{}% error'.format(round(len(train_results[train_results.same==False]) / len(train_results) * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NN on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup inputs:\n",
    "te_i = test.shape[0]\n",
    "test_Xs = test.values[:, :3].reshape((te_i, 3, 1))\n",
    "test_ys = test.values[:,  3].reshape((te_i, 1, 1))\n",
    "print('Shapes of inputs:', test_Xs.shape, test_ys.shape)\n",
    "\n",
    "# Test NN:\n",
    "test_y_preds = NN.predict(x_inputs=test_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check testing predictions:\n",
    "print('Shape of y_preds:', test_y_preds.shape)\n",
    "print(test_y_preds.reshape(test_y_preds.shape[0])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing results:\n",
    "# NB: the y predictions are rounded!\n",
    "test_results = pd.DataFrame({'y_true': test.y.values,\n",
    "                             'y_pred': np.round(test_y_preds).reshape((te_i,)).astype(int),\n",
    "                             'same': test.y.values == np.round(test_y_preds).reshape((te_i,)).astype(int)})\n",
    "\n",
    "display(test_results.head(5))\n",
    "\n",
    "print('{}% error'.format(round(len(test_results[test_results.same==False]) / len(test_results) * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare against NN via scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the sklearn neural network\n",
    "sklearn_NN = MLPClassifier(activation='logistic', solver='sgd', max_iter=1000)  # NB: 'logistic' and stochastic gd chosen for fair comparison.\n",
    "\n",
    "# Optimise parameters via a gridsearch:\n",
    "sklearn_params = {'hidden_layer_sizes': [5, 50, 100], 'learning_rate_init': [0.1, 0.01, 0.001], 'alpha': [0.1, 0.01, 0.001]}\n",
    "sklearn_grid = GridSearchCV(estimator=sklearn_NN, param_grid=sklearn_params, cv=5)\n",
    "\n",
    "# Train sklearn NN:\n",
    "sklearn_grid.fit(X=train.iloc[:, :3].values, y=train.y.values)\n",
    "print('best parameters:\\t{}'.format(sklearn_grid.best_params_))\n",
    "\n",
    "# Test sklearn NN:\n",
    "sklearn_y_preds = sklearn_grid.predict(X=test.iloc[:, :3].values)\n",
    "\n",
    "# Display the sklearn predictions:\n",
    "sklearn_results = pd.DataFrame({'y_true': test.y.values, 'y_pred': sklearn_y_preds, 'same': test.y.values == sklearn_y_preds})\n",
    "display(sklearn_results.head(5))\n",
    "\n",
    "# Print error:\n",
    "print('{}% error'.format(round(len(sklearn_results[sklearn_results.same==False]) / len(sklearn_results) * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('data-science-mlp-D2Uk10-b-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d1c2cbbf11475466136c51493600a516540fe4ec922184bbee37bb507aec1d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
